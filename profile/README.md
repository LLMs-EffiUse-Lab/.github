# LLMs-EffiUse-Lab ğŸš€

<!--
Hi There ğŸ‘‹

Welcome to the **LLMs-EffiUse-Lab** GitHub repository! Our lab is dedicated to optimizing the use of Large Language Models (LLMs) from a user perspective. We focus on developing cost-effective, efficient, and sustainable methodologies to maximize the utilization of LLM services.
-->


## About Us ğŸŒŸ

### Research Focus ğŸ“š
The primary focus of our research includes:
- Optimal Assignment of Queries to LLMs ğŸ¯
- Cost-effective Utilization of LLMs ğŸ’°
- Schedule Optimization for LLM Queries ğŸ“…
- User-centric Approaches to LLM Efficiency ğŸ‘¥
- ğŸŒˆ

### Current Projects ğŸ”¬
- **OptLLM**: A comprehensive framework designed to optimize the allocation of queries to LLM services. It considers both the cost of invocation and performance metrics to provide the best possible query distribution. OptLLM operates in two modes:
  - **OptLLM-S**: Focuses on a single-objective optimization, prioritizing either cost or performance.
  - **OptLLM-M**: Employs a multi-objective optimization strategy, balancing both cost and performance to achieve an optimal trade-off. OptLLM also incorporates robust aware prediction to achieve good prediction performance with a small training data size.

- **CPLS**: A specialized framework that leverages transfer learning and local search techniques to enhance the assignment of jobs to LLM-based services. CPLS addresses the challenge of collecting labels for prediction model training by utilizing transfer learning techniques. 

- **Exploratory Study**: A research initiative exploring the integration of schedule optimization techniques with In-Context Learning (ICL) to further enhance LLM utilization. This study aims to uncover novel strategies for improving the efficiency and effectiveness of LLM deployments.

## Contact Us âœ‰ï¸
For more information, please contact us at [LLMs.EffiUse.Lab@gmail.com](mailto:LLMs.EffiUse.Lab@gmail.com).
