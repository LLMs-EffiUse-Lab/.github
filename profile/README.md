# LLMs-EffiUse-Lab üöÄ

Hi, there üëã Welcome to the **LLMs-EffiUse-Lab** GitHub repository! Our lab is dedicated to optimizing the use of Large Language Models (LLMs) from a user perspective. We focus on developing cost-effective, efficient, and sustainable methodologies to maximize the utilization of LLM services.


## üì¶ Projects

| Project | Description | Related Publication |
|---------|-------------|---------------------|
| [SmartLLMs Scheduler] | Dynamic LLMs Scheduling | [Under review](https://arxiv.org/abs/2508.03258) |
| [OptLLM](https://github.com/LLMs-EffiUse-Lab/OptLLM) | Multi-objective optimization for LLMs Utilization | [ICWS 2025](https://ieeexplore.ieee.org/iel8/10707332/10707376/10707591.pdf) |
| [CPLS](https://github.com/LLMs-EffiUse-Lab/CPLS) | Cross-Project LLMs Scheduling | [ICSME 2024](https://ieeexplore.ieee.org/iel8/10794981/10794987/10795114.pdf) |
| [Exploratory Study](https://github.com/LLMs-EffiUse-Lab/Sched-ICL-Empirical) | Exploratory study for combining schedule optimization with ICL in LLM utilization | [ESEM 2024](https://doi-org.ezproxy.newcastle.edu.au/10.1145/3674805.3686671) |



## About US üåü

### Research Focus üìö
The primary focus of our research includes:
- Cost-effective Utilization of LLMs üí∞
- Schedule Optimization for LLM Queries üìÖ
- User-centric Approaches to LLM Efficiency üë•
- Sustainable Practices üå±

### Current Projects üî¨
- **OptLLM**: A comprehensive framework designed to optimize the allocation of queries to LLM services. It considers both the cost of invocation and performance metrics to provide the best possible query distribution. OptLLM operates in two modes:
  - **OptLLM-S**: Focuses on a single-objective optimization, prioritizing either cost or performance.
  - **OptLLM-M**: Employs a multi-objective optimization strategy, balancing both cost and performance to achieve an optimal trade-off. OptLLM also incorporates robust aware prediction to achieve good prediction performance with a small training data size.

- **CPLS**: A specialized framework that leverages transfer learning and local search techniques to enhance the assignment of jobs to LLM-based services. CPLS addresses the challenge of collecting labels for prediction model training by utilizing transfer learning techniques. 

- **Exploratory Study**: A research initiative exploring the integration of schedule optimization techniques with In-Context Learning (ICL) to further enhance LLM utilization. This study aims to uncover novel strategies for improving the efficiency and effectiveness of LLM deployments.

## Contact Us ‚úâÔ∏è
For more information, please contact us at [LLMs.EffiUse.Lab@gmail.com](mailto:LLMs.EffiUse.Lab@gmail.com).
